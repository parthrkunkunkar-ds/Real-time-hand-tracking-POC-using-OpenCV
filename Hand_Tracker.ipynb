{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d961fdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "OpenCV version: 4.12.0\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc3ca9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Virtual boundary configuration (x, y, width, height)\n",
    "BOUNDARY = {'x': 400, 'y': 150, 'width': 200, 'height': 300}\n",
    "\n",
    "# Distance thresholds (in pixels)\n",
    "DANGER_THRESHOLD = 30\n",
    "WARNING_THRESHOLD = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db71d291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Camera resolution\n",
    "CAMERA_WIDTH = 640\n",
    "CAMERA_HEIGHT = 480\n",
    "\n",
    "# State colors (BGR format for OpenCV)\n",
    "COLOR_SAFE = (0, 255, 0)      # Green\n",
    "COLOR_WARNING = (0, 165, 255) # Orange\n",
    "COLOR_DANGER = (0, 0, 255)    # Red\n",
    "COLOR_BOUNDARY = (255, 255, 0) # Cyan\n",
    "COLOR_HAND = (0, 255, 0)      # Green\n",
    "COLOR_FINGERTIP = (0, 0, 255) # Red\n",
    "\n",
    "print(\"Configuration loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca94e7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skin detection functions defined!\n"
     ]
    }
   ],
   "source": [
    "#  Skin Detection Functions\n",
    "\n",
    "def detect_skin_ycrcb(frame):\n",
    "    \"\"\"\n",
    "    Detect skin using YCrCb color space (more robust than HSV/RGB)\n",
    "    Args:\n",
    "        frame: BGR image from camera \n",
    "    Returns:\n",
    "        Binary mask where white pixels represent detected skin\n",
    "     \"\"\"\n",
    "    # Convert to YCrCb color space\n",
    "    ycrcb = cv2.cvtColor(frame, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    # Define skin color range in YCrCb\n",
    "    # Y: 0-255, Cr: 133-173, Cb: 77-127 (typical skin values)\n",
    "    lower_skin = np.array([0, 133, 77], dtype=np.uint8)\n",
    "    upper_skin = np.array([255, 173, 127], dtype=np.uint8)\n",
    "    \n",
    "    # Create binary mask\n",
    "    mask = cv2.inRange(ycrcb, lower_skin, upper_skin)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def detect_skin_hsv(frame):\n",
    "    \"\"\"\n",
    "    Alternative: Detect skin using HSV color space\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Define skin color range in HSV\n",
    "    lower_skin = np.array([0, 20, 70], dtype=np.uint8)\n",
    "    upper_skin = np.array([20, 255, 255], dtype=np.uint8)\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_skin, upper_skin)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "print(\"Skin detection functions defined!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b747a44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image processing functions defined!\n",
      "Motion detection functions defined!\n"
     ]
    }
   ],
   "source": [
    "#  Image Processing Functions\n",
    "\n",
    "def preprocess_mask(mask):\n",
    "    \"\"\"\n",
    "    Clean up the skin mask using morphological operations\n",
    "    \n",
    "    Args:\n",
    "        mask: Binary mask from skin detection\n",
    "    \n",
    "    Returns:\n",
    "        Cleaned binary mask\n",
    "    \"\"\"\n",
    "    # Create morphological kernels\n",
    "    kernel_erode = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    kernel_dilate = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    \n",
    "    # Erosion to remove noise\n",
    "    mask = cv2.erode(mask, kernel_erode, iterations=2)\n",
    "    \n",
    "    # Dilation to fill gaps\n",
    "    mask = cv2.dilate(mask, kernel_dilate, iterations=2)\n",
    "    \n",
    "    # Gaussian blur to smooth edges\n",
    "    mask = cv2.GaussianBlur(mask, (5, 5), 0)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def find_largest_contour(mask):\n",
    "    \"\"\"\n",
    "    Find the largest contour in the mask (assumed to be the hand)\n",
    "    Filter by position to avoid detecting face\n",
    "    \"\"\"\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Filter contours by position (assume hand is in lower half or sides)\n",
    "    h, w = mask.shape\n",
    "    valid_contours = []\n",
    "    \n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area < 1000:  # Too small\n",
    "            continue\n",
    "        \n",
    "        # Get contour center\n",
    "        M = cv2.moments(contour)\n",
    "        if M['m00'] == 0:\n",
    "            continue\n",
    "        \n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "        \n",
    "        # Filter: prefer contours in lower 2/3 of frame or on sides\n",
    "        # This helps avoid detecting face which is usually in upper-middle\n",
    "        if cy > h * 0.3 or cx < w * 0.3 or cx > w * 0.7:\n",
    "            valid_contours.append((contour, area))\n",
    "    \n",
    "    if len(valid_contours) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Return largest valid contour\n",
    "    largest_contour = max(valid_contours, key=lambda x: x[1])[0]\n",
    "    \n",
    "    return largest_contour\n",
    "\n",
    "print(\"Image processing functions defined!\")\n",
    "\n",
    "#  Motion Detection Functions\n",
    "prev_frame = None\n",
    "\n",
    "def detect_hand_with_motion(frame, skin_mask):\n",
    "    \"\"\"\n",
    "    Combine skin detection with motion detection to focus on moving hand\n",
    "    \"\"\"\n",
    "    global prev_frame\n",
    "    \n",
    "    if prev_frame is None:\n",
    "        prev_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        return skin_mask\n",
    "    \n",
    "    # Convert current frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate frame difference (motion)\n",
    "    frame_diff = cv2.absdiff(prev_frame, gray)\n",
    "    _, motion_mask = cv2.threshold(frame_diff, 25, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Combine skin mask with motion mask\n",
    "    combined_mask = cv2.bitwise_and(skin_mask, motion_mask)\n",
    "    \n",
    "    # Update previous frame\n",
    "    prev_frame = gray.copy()\n",
    "    \n",
    "    return combined_mask\n",
    "print(\"Motion detection functions defined!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c54b624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance and state functions defined!\n"
     ]
    }
   ],
   "source": [
    "#  Distance Calculation and State Classification\n",
    "\n",
    "def calculate_distance_to_boundary(point, boundary):\n",
    "    \"\"\"\n",
    "    Calculate minimum distance from a point to the virtual boundary\n",
    "    \n",
    "    Args:\n",
    "        point: Tuple (x, y) representing the point\n",
    "        boundary: Dictionary with keys x, y, width, height\n",
    "    \n",
    "    Returns:\n",
    "        Distance in pixels\n",
    "    \"\"\"\n",
    "    if point is None:\n",
    "        return float('inf')\n",
    "    \n",
    "    px, py = point\n",
    "    bx, by = boundary['x'], boundary['y']\n",
    "    bw, bh = boundary['width'], boundary['height']\n",
    "    \n",
    "    # Calculate distance to each edge\n",
    "    # If point is inside boundary, distance to closest edge\n",
    "    # If point is outside, distance to closest corner or edge\n",
    "    \n",
    "    # Horizontal distance\n",
    "    if px < bx:\n",
    "        dx = bx - px\n",
    "    elif px > bx + bw:\n",
    "        dx = px - (bx + bw)\n",
    "    else:\n",
    "        dx = 0\n",
    "    \n",
    "    # Vertical distance\n",
    "    if py < by:\n",
    "        dy = by - py\n",
    "    elif py > by + bh:\n",
    "        dy = py - (by + bh)\n",
    "    else:\n",
    "        dy = 0\n",
    "    \n",
    "    # Euclidean distance\n",
    "    distance = np.sqrt(dx**2 + dy**2)\n",
    "    \n",
    "    return distance\n",
    "\n",
    "def classify_state(distance):\n",
    "    \"\"\"\n",
    "    Classify interaction state based on distance\n",
    "    \n",
    "    Args:\n",
    "        distance: Distance to boundary in pixels\n",
    "    \n",
    "    Returns:\n",
    "        State string: 'SAFE', 'WARNING', or 'DANGER'\n",
    "    \"\"\"\n",
    "    if distance < DANGER_THRESHOLD:\n",
    "        return 'DANGER'\n",
    "    elif distance < WARNING_THRESHOLD:\n",
    "        return 'WARNING'\n",
    "    else:\n",
    "        return 'SAFE'\n",
    "\n",
    "print(\"Distance and state functions defined!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eacf0b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization functions defined!\n"
     ]
    }
   ],
   "source": [
    "#  Visualization Functions\n",
    "\n",
    "def draw_boundary(frame, boundary):\n",
    "    \"\"\"\n",
    "    Draw the virtual boundary on the frame\n",
    "    \"\"\"\n",
    "    x, y = boundary['x'], boundary['y']\n",
    "    w, h = boundary['width'], boundary['height']\n",
    "    \n",
    "    # Draw filled rectangle with transparency\n",
    "    overlay = frame.copy()\n",
    "    cv2.rectangle(overlay, (x, y), (x + w, y + h), COLOR_BOUNDARY, -1)\n",
    "    cv2.addWeighted(overlay, 0.1, frame, 0.9, 0, frame)\n",
    "    \n",
    "    # Draw boundary outline\n",
    "    cv2.rectangle(frame, (x, y), (x + w, y + h), COLOR_BOUNDARY, 3)\n",
    "    \n",
    "    # Draw boundary label\n",
    "    cv2.putText(frame, \"VIRTUAL BOUNDARY\", (x, y - 10), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, COLOR_BOUNDARY, 2)\n",
    "\n",
    "def draw_hand_features(frame, features):\n",
    "    \"\"\"\n",
    "    Draw hand contour, hull, center, and fingertip\n",
    "    \"\"\"\n",
    "    if features is None:\n",
    "        return\n",
    "    \n",
    "    # Draw convex hull\n",
    "    cv2.drawContours(frame, [features['hull']], 0, COLOR_HAND, 2)\n",
    "    \n",
    "    # Draw center point\n",
    "    cv2.circle(frame, features['center'], 5, (255, 0, 255), -1)\n",
    "    \n",
    "    # Draw fingertip\n",
    "    cv2.circle(frame, features['fingertip'], 8, COLOR_FINGERTIP, -1)\n",
    "    cv2.circle(frame, features['fingertip'], 12, COLOR_FINGERTIP, 2)\n",
    "    \n",
    "    # Draw line from fingertip to boundary center\n",
    "    boundary_center = (\n",
    "        BOUNDARY['x'] + BOUNDARY['width'] // 2,\n",
    "        BOUNDARY['y'] + BOUNDARY['height'] // 2\n",
    "    )\n",
    "    cv2.line(frame, features['fingertip'], boundary_center, (0, 255, 255), 2)\n",
    "\n",
    "def draw_state_overlay(frame, state, distance, fps):\n",
    "    \"\"\"\n",
    "    Draw state information overlay\n",
    "    \"\"\"\n",
    "    # State color mapping\n",
    "    state_colors = {\n",
    "        'SAFE': COLOR_SAFE,\n",
    "        'WARNING': COLOR_WARNING,\n",
    "        'DANGER': COLOR_DANGER\n",
    "    }\n",
    "    \n",
    "    color = state_colors.get(state, (128, 128, 128))\n",
    "    \n",
    "    # Draw state box\n",
    "    cv2.rectangle(frame, (10, 10), (220, 100), color, -1)\n",
    "    cv2.rectangle(frame, (10, 10), (220, 100), (255, 255, 255), 2)\n",
    "    \n",
    "    # Draw state text\n",
    "    cv2.putText(frame, state, (25, 50), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 0), 3)\n",
    "    cv2.putText(frame, f\"Dist: {int(distance)}px\", (25, 85), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
    "    \n",
    "    # Draw FPS counter\n",
    "    cv2.rectangle(frame, (10, 110), (150, 150), (50, 50, 50), -1)\n",
    "    cv2.rectangle(frame, (10, 110), (150, 150), (255, 255, 255), 2)\n",
    "    cv2.putText(frame, f\"FPS: {fps}\", (25, 137), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    # DANGER warning overlay\n",
    "    if state == 'DANGER':\n",
    "        overlay = frame.copy()\n",
    "        h, w = frame.shape[:2]\n",
    "        cv2.rectangle(overlay, (0, h//2 - 60), (w, h//2 + 60), COLOR_DANGER, -1)\n",
    "        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)\n",
    "        \n",
    "        # Draw DANGER text\n",
    "        cv2.putText(frame, \"DANGER DANGER\", (w//2 - 250, h//2 + 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2.0, (255, 255, 255), 5)\n",
    "\n",
    "def draw_info_panel(frame):\n",
    "    \"\"\"\n",
    "    Draw information panel with instructions\n",
    "    \"\"\"\n",
    "    h, w = frame.shape[:2]\n",
    "    \n",
    "    # Draw semi-transparent background\n",
    "    overlay = frame.copy()\n",
    "    cv2.rectangle(overlay, (w - 250, 10), (w - 10, 200), (40, 40, 40), -1)\n",
    "    cv2.addWeighted(overlay, 0.8, frame, 0.2, 0, frame)\n",
    "    \n",
    "    # Draw border\n",
    "    cv2.rectangle(frame, (w - 250, 10), (w - 10, 200), (200, 200, 200), 2)\n",
    "    \n",
    "    # Draw text\n",
    "    texts = [\n",
    "        \"INSTRUCTIONS:\",\n",
    "        \"Move hand toward\",\n",
    "        \"cyan boundary\",\n",
    "        \"\",\n",
    "        \"Q - Quit\",\n",
    "        \"R - Reset\",\n",
    "        \"S - Screenshot\"\n",
    "    ]\n",
    "    \n",
    "    y_offset = 35\n",
    "    for i, text in enumerate(texts):\n",
    "        cv2.putText(frame, text, (w - 235, y_offset + i * 25), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "print(\"Visualization functions defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9518109a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main function defined!\n",
      "\n",
      "Ready to run! \n"
     ]
    }
   ],
   "source": [
    "#  Main Processing Loop\n",
    "\n",
    "def run_hand_tracking():\n",
    "    \"\"\"\n",
    "    Main function to run the hand tracking danger detection system\n",
    "    \"\"\"\n",
    "    # Initialize camera\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAMERA_WIDTH)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAMERA_HEIGHT)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open camera!\")\n",
    "        return\n",
    "    \n",
    "    print(\"Camera initialized successfully!\")\n",
    "    print(\"Controls:\")\n",
    "    print(\"  Q - Quit\")\n",
    "    print(\"  R - Reset\")\n",
    "    print(\"  S - Save screenshot\")\n",
    "    print(\"\\nMove your hand toward the cyan boundary to trigger warnings...\")\n",
    "    \n",
    "    # FPS calculation variables\n",
    "    fps = 0\n",
    "    frame_count = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    while True:\n",
    "        # Capture frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture frame!\")\n",
    "            break\n",
    "        \n",
    "        # Flip frame horizontally for mirror effect\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # Step 1: Detect skin\n",
    "        skin_mask = detect_skin_ycrcb(frame)\n",
    "        skin_mask = detect_hand_with_motion(frame, skin_mask)  # Add motion filtering\n",
    "        \n",
    "        # Step 2: Preprocess mask\n",
    "        clean_mask = preprocess_mask(skin_mask)\n",
    "        \n",
    "        # Step 3: Find hand contour\n",
    "        hand_contour = find_largest_contour(clean_mask)\n",
    "        \n",
    "        # Step 4: Extract hand features\n",
    "        hand_features = get_hand_features(hand_contour)\n",
    "        \n",
    "        # Step 5: Calculate distance and classify state\n",
    "        if hand_features:\n",
    "            fingertip = hand_features['fingertip']\n",
    "            distance = calculate_distance_to_boundary(fingertip, BOUNDARY)\n",
    "            state = classify_state(distance)\n",
    "        else:\n",
    "            distance = float('inf')\n",
    "            state = 'NO HAND DETECTED'\n",
    "        \n",
    "        # Step 6: Visualization\n",
    "        draw_boundary(frame, BOUNDARY)\n",
    "        draw_hand_features(frame, hand_features)\n",
    "        draw_state_overlay(frame, state, distance, fps)\n",
    "        draw_info_panel(frame)\n",
    "        \n",
    "        # Calculate FPS\n",
    "        frame_count += 1\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time > 1.0:\n",
    "            fps = int(frame_count / elapsed_time)\n",
    "            frame_count = 0\n",
    "            start_time = time.time()\n",
    "        \n",
    "        # Display frame\n",
    "        cv2.imshow('Hand Tracking Danger Detection', frame)\n",
    "        \n",
    "        # Optional: Show skin mask for debugging\n",
    "        # cv2.imshow('Skin Mask', clean_mask)\n",
    "        \n",
    "        # Handle keyboard input\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if key == ord('q') or key == 27:  # Q or ESC to quit\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "        elif key == ord('r'):  # R to reset\n",
    "            print(\"Reset...\")\n",
    "        elif key == ord('s'):  # S to save screenshot\n",
    "            filename = f\"screenshot_{int(time.time())}.jpg\"\n",
    "            cv2.imwrite(filename, frame)\n",
    "            print(f\"Screenshot saved: {filename}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Camera released and windows closed.\")\n",
    "\n",
    "print(\"Main function defined!\")\n",
    "print(\"\\nReady to run! \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fb19b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera initialized successfully!\n",
      "Controls:\n",
      "  Q - Quit\n",
      "  R - Reset\n",
      "  S - Save screenshot\n",
      "\n",
      "Move your hand toward the cyan boundary to trigger warnings...\n",
      "Exiting...\n",
      "Camera released and windows closed.\n"
     ]
    }
   ],
   "source": [
    "#  Run the System\n",
    "\n",
    "run_hand_tracking()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
